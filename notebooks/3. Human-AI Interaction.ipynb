{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e848c400",
   "metadata": {},
   "source": [
    "# 3. Human-AI Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318109d",
   "metadata": {},
   "source": [
    "***Your information:***\n",
    "* Name:     Yugal Jagtap\n",
    "* UBT ID:   bt727466\n",
    "* E-Mail:   bt727466@uni-bayreuth.de\n",
    "<br>\n",
    "I confirm the solution in this notebook is my own work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8b508",
   "metadata": {},
   "source": [
    "**Background:**<br>\n",
    "Problems with the COMPAS case do not only arise from the software, but also with how judges use the software. With the analysis of task 1 and 2 in mind, you want to consult Northpointe and judges on how to effectively deploy the COMPAS risk scores for productive use. For this purpose you apply what you learned about human-AI interaction and cognitive biases.\n",
    "\n",
    "**Objective:**<br>\n",
    "As a showcase, you deploy your surrogate model and build a prototpyical interface that steers the human-AI interaction. The human-AI interaction should explicitly account for biases and limitations of your surrogate model as well as biases and limitations of judges.\n",
    "\n",
    "**Deliverables:**<br>\n",
    "1. Briefly comment on general concerns you have with using recidivism prediction software in a legal system. Given COMPAS software is still in use in the US, what safeguards should there be to reduce ethical and societal risks?\n",
    "2. Create a web (`localhost`) interface that deploys your surrogate model and predicts a risk score for submitted defendant profiles.\n",
    "3. In bullet-points, sketch a human-AI interaction framework (not in code!) that explicitly accounts for the anticipated biases and limitations of both your surrogate model and the judges interacting with it. It must include a model prediction and a final decision, but you are free about the roles, sequences, explanations, visualizations etc.\n",
    "4. Discuss, how your design choices reduce the risks.\n",
    "5. Integrate **at least one** of your design choices in your deployed interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4868a",
   "metadata": {},
   "source": [
    "## 1. Concerns with Recidivism Prediction Software:\n",
    "* **Bias Perpetuation:** Algorithms trained on historical arrest data may learn and reinforce existing racial and socioeconomic biases. As seen with COMPAS, this can lead to higher False Positive Rates for certain demographic groups (e.g., African-Americans).\n",
    "* **Lack of Transparency:** Proprietary algorithms (\"black boxes\") make it difficult for defendants and defense attorneys to challenge the validity of the risk score.\n",
    "* **Automation Bias:** Judges may over-rely on the algorithm's output, treating it as objective truth rather than a probabilistic estimate, effectively delegating judicial discretion to a machine.\n",
    "\n",
    "**Safeguards for Ethical Use:**\n",
    "* **Explainability:** Systems must provide interpretable reasons for their scores (e.g., \"Risk high due to X prior convictions\") rather than just a number.\n",
    "* **Mandatory Human-in-the-Loop:** Risk scores should never automatically determine sentencing; they should serve only as one of many factors considered by a human judge.\n",
    "* **Training**: Stakeholders (judges, lawyers) must be trained on the limitations and statistical meaning of these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hci_framework",
   "metadata": {},
   "source": [
    "## 2. Human-AI Interaction Framework\n",
    "**Framework Sketch:**\n",
    "\n",
    "* **Role Definition:** \n",
    "    * **AI:** Decision Support / Second Opinion. NOT the decision maker.\n",
    "    * **Judge:** Final Decision Maker / Arbiter of Context.\n",
    "\n",
    "* **Interaction Sequence:**\n",
    "    1. **Case Review:** Judge acknowledges case details *before* seeing the AI score (to form an independent initial impression).\n",
    "    2. **AI Input:** Judge requests AI assessment.\n",
    "    3. **Presentation:** AI presents Risk Score, **Confidence Interval**, and **Top 3 Contributing Factors** (Why is this score high?).\n",
    "    4. **Bias Alert:** If the defendant belongs to a group with known high FPR, display a specific \"Bias Caution\" warning.\n",
    "    5. **Decision:** Judge enters final decision. If the decision aligns with a high-risk AI score but the defendant has few priors, the system prompts for a briefly typed justification (forcing cognitive engagement)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discussion",
   "metadata": {},
   "source": [
    "## 3. Design Choices\n",
    "* **Addressing Automation Bias:** By forcing the judge to review the case *before* seeing the score, we reduce the anchoring effect where the judge creates a mental narrative to fit the AI's score. The \"justification prompt\" for contentious decisions adds constructive friction, forcing the judge to think critically rather than passively accepting the AI's suggestion.\n",
    "* **Addressing Transparency:** Showing \"Contributing Factors\" moves the system from a black box to a glass box, allowing the judge to spot if the AI is relying on proxies for race (e.g., zip code) or irrelevant data.\n",
    "* **Addressing Fairness:** The \"Bias Alert\" explicitly reminds the user of the model's known limitations regarding specific demographics, encouraging a more cautious interpretation of high-risk scores for those groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flask_app_instructions",
   "metadata": {},
   "source": [
    "## 4. Deployed Interface\n",
    "The following cell contains the code to run the Flask application directly from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flask_app_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Models loaded successfully.\n",
      "Starting Flask app...\n",
      "Go to http://127.0.0.1:5000 to view the app.\n",
      "Interrupt the kernel to stop the server.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [17/Feb/2026 10:32:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:32:26] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:32:55] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:33:00] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:33:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:33:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Feb/2026 10:33:42] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from flask import Flask, render_template, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Initializing Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Loading Models\n",
    "MODEL_DIR = 'models'\n",
    "try:\n",
    "    print(\"Loading models...\")\n",
    "    tabular_model = joblib.load(os.path.join(MODEL_DIR, 'tabular_model.pkl'))\n",
    "    text_model = joblib.load(os.path.join(MODEL_DIR, 'text_model.pkl'))\n",
    "    meta_model = joblib.load(os.path.join(MODEL_DIR, 'meta_model.pkl'))\n",
    "    print(\"Models loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Extracting features from form\n",
    "        data = {\n",
    "            'age': [int(request.form['age'])],\n",
    "            'sex': [request.form['sex']],\n",
    "            'race': [request.form['race']],\n",
    "            'priors_count': [int(request.form['priors_count'])],\n",
    "            'juv_fel_count': [int(request.form['juv_fel_count'])],\n",
    "            'juv_misd_count': [int(request.form['juv_misd_count'])],\n",
    "            'juv_other_count': [int(request.form['juv_other_count'])],\n",
    "            'c_charge_degree': [request.form['c_charge_degree']],\n",
    "            'c_charge_desc': [request.form['c_charge_desc']],\n",
    "            'days_b_screening_arrest': [float(request.form['days_b_screening_arrest'])],\n",
    "            'c_days_from_compas': [float(request.form['c_days_from_compas'])]\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        X_input = pd.DataFrame(data)\n",
    "        \n",
    "        # Generate Predictions\n",
    "        # 1. Tabular Model Probs\n",
    "        tab_probs = tabular_model.predict_proba(X_input)\n",
    "        \n",
    "        # 2. Text Model Probs\n",
    "        text_probs = text_model.predict_proba(X_input['c_charge_desc'].astype(str))\n",
    "        \n",
    "        # 3. Meta Features\n",
    "        meta_features = np.hstack((tab_probs, text_probs))\n",
    "        \n",
    "        # 4. Final Prediction\n",
    "        prediction = meta_model.predict(meta_features)[0]\n",
    "        \n",
    "        # Determine visual feedback\n",
    "        score = int(prediction)\n",
    "        risk_level = \"Low\"\n",
    "        risk_class = \"low-risk\"\n",
    "        \n",
    "        if score > 4 and score <= 7:\n",
    "            risk_level = \"Medium\"\n",
    "            risk_class = \"medium-risk\"\n",
    "        elif score > 7:\n",
    "            risk_level = \"High\"\n",
    "            risk_class = \"high-risk\"\n",
    "\n",
    "        return render_template('result.html', score=score, risk_level=risk_level, risk_class=risk_class)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during prediction: {e}\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting Flask app...\")\n",
    "    print(\"Go to http://127.0.0.1:5000 to view the app.\")\n",
    "    print(\"Interrupt the kernel to stop the server.\")\n",
    "    app.run(port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13593d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
